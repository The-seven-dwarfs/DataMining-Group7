{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' # to print multiple outputs from the same cell\n",
    "import math\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from operator import index\n",
    "from collections import defaultdict\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(\"dataset/users.csv\")\n",
    "#tweets_df = pd.read_csv(\"dataset/tweets.csv\", usecols=[\"id\", \"user_id\"]) # read only this two colums (saving space)\n",
    "tweets_df = pd.read_csv(\"dataset/tweets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Users Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In users.csv there are the following variables:\n",
    "1. User Id: a unique identifier of the user\n",
    "2. Statues Count: According to the teacher, this is the count of the tweets made by the user at the moment of data\n",
    "crawling. According to [Twitter API docs](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/user), this is the number of Tweets (including retweets) issued by the user, but not replies (according to Francesca Naretto); since tweets.csv inclues also users' replies note that **there is no link between the number of tweets for each user in tweets.csv and statuses_count**.\n",
    "3. Lang: the user’s language selected\n",
    "4. Created at: the timestamp in which the profile was created\n",
    "5. Label: a binary variable that indicates if a user is a bot or a genuine user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute type and quality\n",
    "\n",
    "In the **user** dataset there are 6 columns:\n",
    "\n",
    "1. The id **column** seems to be ok, all values are integer and there are not null values, we have to check possible duplicates\n",
    " \n",
    "2. We have 1 null value in the **name** column, we also assume that the name could be a string, a number or a special character, the names are not necessarily unique, but maybe it's intresting to check the frequency distribution.\n",
    "\n",
    "3. In the **lang** column we don't have null values, but we have to check whether there are problems in the pattern used to express the language, we expect a categorical attribute \n",
    "\n",
    "4. The **bot** column is numerical as expected (binary), we have to check whether all the numbers are 0 or 1\n",
    "\n",
    "5. The attribute **created_at** has no null values, but we have to check the correctness of the date, both sintactic and semantic (not too far in the past or in the future)\n",
    "\n",
    "6. The **status_count** column has 399 of null values, in the non-null values there would semm to be unexpected float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the uniqueness of ids: all the ids are unique!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total IDs: 11508\n",
      "Number of unique IDs: 11508\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of total IDs:\", len(users_df[\"id\"]))\n",
    "print(\"Number of unique IDs:\", len(pd.unique(users_df[\"id\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before one name is null. There are also duplicate names, but this isn't a surprising behaviour and by plotting the names' frequencies we can see that there aren't strange phenomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of total names:\", len(users_df[\"name\"]))\n",
    "print(\"Number of unique names:\", len(pd.unique(users_df[\"name\"])))\n",
    "\n",
    "freq = {}\n",
    "for n in users_df['name']:\n",
    "    if n in freq:\n",
    "        freq[n] += 1\n",
    "    else:\n",
    "        freq[n] = 1\n",
    "\n",
    "number_of_total_names = len(users_df[\"name\"])\n",
    "not_empty_or_missing_names = []\n",
    "empty_or_missing_names = []\n",
    "names_with_only_spaces = []\n",
    "\n",
    "# iterate over all names looking for errors\n",
    "for value in users_df[\"name\"]:\n",
    "    if pd.isna(value) or value == \"\": # name is nan or is_empty string\n",
    "        empty_or_missing_names.append(value)\n",
    "    if str(value).strip() == \"\":\n",
    "            names_with_only_spaces.append(value)\n",
    "    elif not(pd.isna(value) or value == \"\"):\n",
    "        not_empty_or_missing_names.append(value)\n",
    "        \n",
    "print(f\"Number of total names = {number_of_total_names} vs total name values that are not NA or empty = {len(not_empty_or_missing_names)}\")\n",
    "print(f\"Number of total names = {number_of_total_names} vs total name values that are NA or empty = {len(empty_or_missing_names)}\")\n",
    "\n",
    "pd.DataFrame({\"frequencies\": [_ for _ in freq.values()]}).hist(\n",
    "    column=[\"frequencies\"], \n",
    "    log=True, \n",
    "    bins=utils.get_sturges_bins(len(freq.values()))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check the lang column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(users_df[\"lang\"])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"lang\" field is composed of [IETF language codes](https://en.wikipedia.org/wiki/IETF_language_tag). By selecting only the unique values it's possible to see that there are some erroneous values:\n",
    "* \"Select Language...\" and \"xx-lc\" seems to be **default values**\n",
    "* other values are not properly correct (e.g. \"zh-cn\" instead of \"zh-CN\")\n",
    "We propose to check the most common language used by these 'erroneous values' users and provide them with a more fitting language attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.repair_lang_attribute(users_df)\n",
    "pd.unique(users_df[\"lang\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since wrong values are just the 0.02% of the number of rows they are just dropped, while the other values are mapped to the correct ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bot attribute is perfectly as expected, all non-null binary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(users_df[\"bot\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the created_at coloumn is recognized by pandas as an object, and not as a datetime as we would expect from this attribute. Clean created_at field, by converting string to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing string to datetime obj\n",
    "users_df[\"created_at\"] = pd.to_datetime(users_df[\"created_at\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the statuses count to be an integer, but pandas has interpreted it as a float. This is probably due to the presence of NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.statuses_count = users_df.statuses_count.apply(pd.to_numeric, errors=\"coerce\").astype({\"statuses_count\": \"Int64\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11508 entries, 0 to 11507\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   id              11508 non-null  int64 \n",
      " 1   name            11507 non-null  object\n",
      " 2   lang            11508 non-null  object\n",
      " 3   bot             11508 non-null  int64 \n",
      " 4   created_at      11508 non-null  object\n",
      " 5   statuses_count  11109 non-null  Int64 \n",
      "dtypes: Int64(1), int64(2), object(3)\n",
      "memory usage: 2.5 MB\n"
     ]
    }
   ],
   "source": [
    "users_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.hist(\n",
    "    column=[\"statuses_count\"], \n",
    "    log=True, \n",
    "    bins=utils.get_sturges_bins(len(users_df[\"statuses_count\"]))\n",
    ")\n",
    "\n",
    "users_df.hist(\n",
    "    column=[\"statuses_count\"], \n",
    "    by=\"bot\", \n",
    "    log=True,\n",
    "    bins=utils.get_sturges_bins(len(users_df[\"statuses_count\"])) #FIX THIS: USES ALL THE SAMPLES, NOT JUST THE BOTS AND THE USERS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = pd.unique(users_df[\"lang\"]) \n",
    "bot_freqs = []\n",
    "user_freqs = []\n",
    "for lang in langs:\n",
    "    user_freqs.append(len(users_df.query(f\"lang == '{lang}' & bot == 0\")))\n",
    "    bot_freqs.append(len(users_df.query(f\"lang == '{lang}' & bot == 1\")))\n",
    "langs_df = pd.DataFrame({\"lang\": langs, \"bot_freqs\": bot_freqs, \"user_freqs\": user_freqs})\n",
    "langs_df.plot.bar(x=\"lang\", logy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In tweets.csv each row contains information about a single tweet. In this case the variables\n",
    "are:\n",
    "1. ID: a unique identifier for the tweet\n",
    "2. User Id: a unique identifier for the user who wrote the tweet\n",
    "3. Retweet count: number of retweets for the tweet in analysis\n",
    "4. Reply count: number of reply for the tweet in analysis\n",
    "5. Favorite count: number of favorites (likes) received by the tweet\n",
    "6. Num hashtags: number of hashtags used in the tweet\n",
    "7. Num urls: number of urls in the tweet\n",
    "8. Num mentions: number of mentions in the tweet\n",
    "9. Created at: when the tweet was created\n",
    "10. Text: the text of the tweet\n",
    "\n",
    "Regarding the num * fields, we don't have to check the validity of the values and can assume they are correct, except for the null and clear incorrect values. In order to substitute the null values of these fields we can exploit the information of the text (however for the mentions and urls it is impossible to check their validity because we may have a mention to a user that does not exist and we cannot know it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing data quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13664696 entries, 0 to 13664695\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count     Dtype \n",
      "---  ------          --------------     ----- \n",
      " 0   id              13664694 non-null  object\n",
      " 1   user_id         13447413 non-null  object\n",
      " 2   retweet_count   13227562 non-null  object\n",
      " 3   reply_count     13016818 non-null  object\n",
      " 4   favorite_count  13017154 non-null  object\n",
      " 5   num_hashtags    12607172 non-null  object\n",
      " 6   num_urls        13016073 non-null  object\n",
      " 7   num_mentions    12810531 non-null  object\n",
      " 8   created_at      13664696 non-null  object\n",
      " 9   text            13126975 non-null  object\n",
      "dtypes: object(10)\n",
      "memory usage: 8.9 GB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info(verbose=True, show_counts=True, memory_usage= \"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keeping only the tweets with user_id in user dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Series.dropna() got an unexpected keyword argument 'subset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     ids_are_not_in_users_df\u001b[38;5;241m.\u001b[39mdropna(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ids_are_not_in_users_df\n\u001b[0;32m----> 9\u001b[0m invalid_users \u001b[38;5;241m=\u001b[39m \u001b[43mget_tweets_id_with_invalid_user\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtweets_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m tweets_df\u001b[38;5;241m.\u001b[39mdrop(invalid_users\u001b[38;5;241m.\u001b[39mindex, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m tweets_df\u001b[38;5;241m.\u001b[39minfo(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn [14], line 6\u001b[0m, in \u001b[0;36mget_tweets_id_with_invalid_user\u001b[0;34m(tweets_df)\u001b[0m\n\u001b[1;32m      4\u001b[0m tmp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_numeric(tweets_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m ids_are_not_in_users_df \u001b[38;5;241m=\u001b[39m tmp[tmp\u001b[38;5;241m.\u001b[39misin(users_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[0;32m----> 6\u001b[0m \u001b[43mids_are_not_in_users_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ids_are_not_in_users_df\n",
      "File \u001b[0;32m~/Scrivania/Università/DM/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    312\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    313\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    314\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    315\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()),\n\u001b[1;32m    316\u001b[0m     )\n\u001b[0;32m--> 317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Series.dropna() got an unexpected keyword argument 'subset'"
     ]
    }
   ],
   "source": [
    "def get_tweets_id_with_invalid_user(tweets_df):\n",
    "    tmp = pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\")\n",
    "    ids_are_not_in_users_df = tmp[tmp.isin(users_df[\"id\"]) == False]\n",
    "    return ids_are_not_in_users_df\n",
    "\n",
    "invalid_users = get_tweets_id_with_invalid_user(tweets_df)\n",
    "\n",
    "tweets_df.drop(invalid_users.index, inplace=True)\n",
    "tweets_df.info(verbose=True)\n",
    "\n",
    "del invalid_users\n",
    "\n",
    "#pd.to_numeric(tweets_df[\"user_id\"], errors=\"coerce\").info(verbose=True, show_counts=True)\n",
    "\n",
    "\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean id field by first removing nan values (just 2), then tring to cast to int and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.dropna(subset=[\"id\"], inplace=True)\n",
    "\n",
    "# removing not numeric strings\n",
    "#pd.to_numeric(tweets_df[\"id\"])\n",
    "\n",
    "#tweets_df[\"id\"].isin(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the method above we observe that all our atributes except for \"created_at\" have one or more elements with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "wrong_ids = []\n",
    "for (i,k) in enumerate(df[\"id\"]):\n",
    "    if not isinstance(k, str) or not k.isnumeric():\n",
    "        wrong_ids.append(i)\n",
    "print(len(wrong_ids)/len(df[\"id\"]))\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checks if all the tweets were created after the first tweet published on twitter (so we don't have something strange like a tweet created in 01-01-1990)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks if all the users were created after the first tweet published on twitter (so we don't have something strange like a user created in 01-01-1990)\n",
    "twitter_first_tweet_datetime = datetime(2006,3,21,12,50,0)\n",
    "#string_to_datetime = lambda string: datetime.strptime(string, expected_format)\n",
    "published_after_twitter_first_tweet = lambda x: x > twitter_first_tweet_datetime\n",
    "all(map(published_after_twitter_first_tweet, users_df[\"created_at\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of variables and statistics\n",
    "Let's study them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should we use sturgen rule for number of bins?\n",
    "\n",
    "# give error: ValueError: hist method requires numerical or datetime columns, nothing to plot.\n",
    "#tweets_df.hist(column=[\"reply_count\",\"retweet_count\", \"favorite_count\", \"num_hashtags\", \"num_urls\", \"num_mentions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables trasformations (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise correlations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
